---
layout: publication
authors:
  - <b>Shivani Kumar</b>
  - David Jurgens
<!-- awards:
  - Invited to SIGGRAPH 2016 -->
highlight: true
link: https://github.com/shivanik96/UniMoral
pdf: https://arxiv.org/abs/2502.14083
<!-- short_doi: 10/bdsz -->
tags:
  - Are Rules Meant to be Broken? Understanding Multilingual Moral Reasoning as a Computational Pipeline with UniMoral
  - Shivani Kumar
  - David Jurgens
  - Preprint
  - Arxiv
  - 2025
title: "Are Rules Meant to be Broken? Understanding Multilingual Moral Reasoning as a Computational Pipeline with UniMoral"
<!-- tweet: Visualization recommendation promotes breadth and prevents early fixation. -->
type:
  - Conference
venue: ACL
venue_location: Vienna, Austria
venue_tags:
  - ACL
<!-- venue_url: http://ieeevis.org/ -->
<!-- video: https://vimeo.com/135417594 -->
year: 2025
date: 2025-05-15
awards: "Best Resource Paper"
---

Moral reasoning is a complex cognitive process shaped by individual experiences and cultural contexts and presents unique challenges for computational analysis. While natural language processing (NLP) offers promising tools for studying this phenomenon, current research lacks cohesion, employing discordant datasets and tasks that examine isolated aspects of moral reasoning. We bridge this gap with UniMoral, a unified dataset integrating psychologically grounded and social-media-derived moral dilemmas annotated with labels for action choices, ethical principles, contributing factors, and consequences, alongside annotators' moral and cultural profiles. Recognizing the cultural relativity of moral reasoning, UniMoral spans six languages, Arabic, Chinese, English, Hindi, Russian, and Spanish, capturing diverse socio-cultural contexts. We demonstrate UniMoral's utility through a benchmark evaluations of three large language models (LLMs) across four tasks: action prediction, moral typology classification, factor attribution analysis, and consequence generation. Key findings reveal that while implicitly embedded moral contexts enhance the moral reasoning capability of LLMs, there remains a critical need for increasingly specialized approaches to further advance moral reasoning in these models.